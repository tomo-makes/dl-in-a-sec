{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EUwJxFJnxqI5"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Hub Authors.\n",
    "\n",
    "##### Modifications Copyright 2019 Tomoaki Masuda.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uKhZrWgRxqI7"
   },
   "outputs": [],
   "source": [
    "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートブックは、以下のノートブックを元に日本語訳、一部章立ての再構成、加筆を行いました。\n",
    "https://github.com/tensorflow/hub/blob/master/examples/colab/tf_hub_delf_module.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mtzhXyaTxqI-"
   },
   "source": [
    "\n",
    "#  DELFとTensorFlow Hubを使って類似画像をさがす"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kZFxcVC9xqJA"
   },
   "source": [
    "\n",
    " TensorFlow Hub（TF-Hub）は、機械学習の専門知識、特に事前学習済みの**モジュール群**を、再利用可能なリソースとしてパッケージ化し、共有するためのプラットフォームです。 \n",
    "\n",
    "このチュートリアルでは、画像を処理し、特徴点(keypoint)とそれらの特徴量記述(keypoint descriptors)を識別する[DELF](https://github.com/tensorflow/models/tree/master/research/delf)ニューラルネットワークとロジックをパッケージ化したモジュールを使います。ニューラルネットワークの重みは、ランドマーク画像を用いて学習したものです。詳細は、 [この論文](https://arxiv.org/abs/1612.06321)で説明しています。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. 環境を準備する\n",
    "\n",
    "必要なライブラリのインストール、インポートを行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "894pu9djxqJA"
   },
   "outputs": [],
   "source": [
    "#@title Update the versions of TF and TF-Hub, if needed.\n",
    "\n",
    "!pip install -q 'tensorflow>=1.7'\n",
    "!pip install -q 'tensorflow-hub>=0.1.0'\n",
    "!pip install -q 'scikit-image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tpMltss-xqJC"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "from scipy.spatial import cKDTree\n",
    "from skimage.feature import plot_matches\n",
    "from skimage.measure import ransac\n",
    "from skimage.transform import AffineTransform\n",
    "from six import BytesIO\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from six.moves.urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i34O5-HTxqJF"
   },
   "source": [
    "\n",
    "## B. データセットを準備する\n",
    "\n",
    "次のセルでは、DELFで、比較し一致を確認したい2つの画像のURLを指定します。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7bKcCZgBxqJG"
   },
   "outputs": [],
   "source": [
    "IMAGE_1_URL = 'https://upload.wikimedia.org/wikipedia/commons/2/28/Bridge_of_Sighs%2C_Oxford.jpg'\n",
    "IMAGE_2_URL = 'https://upload.wikimedia.org/wikipedia/commons/c/c3/The_Bridge_of_Sighs_and_Sheldonian_Theatre%2C_Oxford.jpg'\n",
    "\n",
    "IMAGE_1_URL = 'https://upload.wikimedia.org/wikipedia/commons/1/1e/Golden_gate2.jpg'\n",
    "IMAGE_2_URL = 'https://upload.wikimedia.org/wikipedia/commons/3/3e/GoldenGateBridge.jpg'\n",
    "\n",
    "IMAGE_1_URL = 'https://upload.wikimedia.org/wikipedia/commons/c/ce/2006_01_21_Ath%C3%A8nes_Parth%C3%A9non.JPG'\n",
    "IMAGE_2_URL = 'https://upload.wikimedia.org/wikipedia/commons/5/5c/ACROPOLIS_1969_-_panoramio_-_jean_melis.jpg'\n",
    "\n",
    "# IMAGE_1_URL = 'https://upload.wikimedia.org/wikipedia/commons/d/d8/Eiffel_Tower%2C_November_15%2C_2011.jpg'\n",
    "# IMAGE_2_URL = 'https://upload.wikimedia.org/wikipedia/commons/a/a8/Eiffel_Tower_from_immediately_beside_it%2C_Paris_May_2008.jpg'\n",
    "\n",
    "# IMAGE_1_URL = 'https://upload.wikimedia.org/wikipedia/commons/2/2d/Parthenon-Restoration-Nov-2005-a.jpg'\n",
    "# IMAGE_2_URL = 'https://upload.wikimedia.org/wikipedia/commons/5/57/White_House_06.02.08.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. データセットを前処理する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qd6bgSfAxqJI"
   },
   "source": [
    "\n",
    "画像をダウンロード、サイズ変更、保存および表示します。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTWJXj5KxqJJ"
   },
   "outputs": [],
   "source": [
    "# The names that will be used for the resized local images.\n",
    "\n",
    "IMAGE_1_JPG = 'image_1.jpg'\n",
    "IMAGE_2_JPG = 'image_2.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xASgQ4PxxqJL"
   },
   "outputs": [],
   "source": [
    "#@title The images that will be processed by DELF\n",
    "def download_and_resize_image(url, filename, new_width=256, new_height=256):\n",
    "  response = urlopen(url)\n",
    "  image_data = response.read()\n",
    "  image_data = BytesIO(image_data)\n",
    "  pil_image = Image.open(image_data)\n",
    "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
    "  pil_image_rgb = pil_image.convert('RGB')\n",
    "  pil_image_rgb.save(filename, format='JPEG', quality=90)\n",
    "\n",
    "download_and_resize_image(IMAGE_1_URL, IMAGE_1_JPG)\n",
    "download_and_resize_image(IMAGE_2_URL, IMAGE_2_JPG)\n",
    "\n",
    "def show_images(image_path_list):\n",
    "  plt.figure()\n",
    "  for i, image_path in enumerate(image_path_list):\n",
    "    plt.subplot(1, len(image_path_list), i+1)\n",
    "    plt.imshow(np.asarray(Image.open(image_path)))\n",
    "    plt.title(image_path)\n",
    "    plt.grid(False)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "  plt.show()\n",
    "\n",
    "show_images([IMAGE_1_JPG, IMAGE_2_JPG])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xo750KNrxqJP"
   },
   "source": [
    "\n",
    "次に、TensorFlowで処理できるように、画像をテンソルに読み込む関数を定義します。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xIfOOF_sxqJP"
   },
   "outputs": [],
   "source": [
    "def image_input_fn():\n",
    "  filename_queue = tf.train.string_input_producer(\n",
    "      [IMAGE_1_JPG, IMAGE_2_JPG], shuffle=False)\n",
    "  reader = tf.WholeFileReader()\n",
    "  _, value = reader.read(filename_queue)\n",
    "  image_tf = tf.image.decode_jpeg(value, channels=3)\n",
    "  return tf.image.convert_image_dtype(image_tf, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BgslMwZExqJS"
   },
   "source": [
    "\n",
    "## D. モデルを取得する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. DELFモジュールを適用する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JnBBo8y0xqJU"
   },
   "source": [
    "\n",
    " DELFモジュールは画像を入力として取り、特徴点をベクトルで記述します。次のセルには、このチュートリアルの中核となるロジックがあります。 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_5MInqhvxqJU"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "tf.logging.set_verbosity(tf.logging.FATAL)\n",
    "\n",
    "m = hub.Module('https://tfhub.dev/google/delf/1')\n",
    "\n",
    "# The module operates on a single image at a time, so define a placeholder to\n",
    "# feed an arbitrary image in.\n",
    "image_placeholder = tf.placeholder(\n",
    "    tf.float32, shape=(None, None, 3), name='input_image')\n",
    "\n",
    "module_inputs = {\n",
    "    'image': image_placeholder,\n",
    "    'score_threshold': 100.0,\n",
    "    'image_scales': [0.25, 0.3536, 0.5, 0.7071, 1.0, 1.4142, 2.0],\n",
    "    'max_feature_num': 1000,\n",
    "}\n",
    "\n",
    "module_outputs = m(module_inputs, as_dict=True)\n",
    "\n",
    "image_tf = image_input_fn()\n",
    "\n",
    "with tf.train.MonitoredSession() as sess:\n",
    "  results_dict = {}  # Stores the locations and their descriptors for each image\n",
    "  for image_path in [IMAGE_1_JPG, IMAGE_2_JPG]:\n",
    "    image = sess.run(image_tf)\n",
    "    print('Extracting locations and descriptors from %s' % image_path)\n",
    "    results_dict[image_path] = sess.run(\n",
    "        [module_outputs['locations'], module_outputs['descriptors']],\n",
    "        feed_dict={image_placeholder: image})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E. モデルを学習させる\n",
    "\n",
    "学習済みモデルを使うため、ここでは行いません。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F. 学習済みモデルを評価する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EAyn7cLxxqJX"
   },
   "source": [
    "\n",
    "### 1. 画像の一致する点を判定する\n",
    "\n",
    "先ほど準備した学習済みのDELFモジュールを使って画像から抽出した、位置とベクトルで記述された特徴点を使い、画像の一致する点を判定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgKpxdSwxqJX"
   },
   "outputs": [],
   "source": [
    "#@title TensorFlow is not needed for this post-processing and visualization\n",
    "def match_images(results_dict, image_1_path, image_2_path):\n",
    "  distance_threshold = 0.8\n",
    "\n",
    "  # Read features.\n",
    "  locations_1, descriptors_1 = results_dict[image_1_path]\n",
    "  num_features_1 = locations_1.shape[0]\n",
    "  print(\"Loaded image 1's %d features\" % num_features_1)\n",
    "  locations_2, descriptors_2 = results_dict[image_2_path]\n",
    "  num_features_2 = locations_2.shape[0]\n",
    "  print(\"Loaded image 2's %d features\" % num_features_2)\n",
    "\n",
    "  # Find nearest-neighbor matches using a KD tree.\n",
    "  d1_tree = cKDTree(descriptors_1)\n",
    "  _, indices = d1_tree.query(\n",
    "      descriptors_2, distance_upper_bound=distance_threshold)\n",
    "\n",
    "  # Select feature locations for putative matches.\n",
    "  locations_2_to_use = np.array([\n",
    "      locations_2[i,]\n",
    "      for i in range(num_features_2)\n",
    "      if indices[i] != num_features_1\n",
    "  ])\n",
    "  locations_1_to_use = np.array([\n",
    "      locations_1[indices[i],]\n",
    "      for i in range(num_features_2)\n",
    "      if indices[i] != num_features_1\n",
    "  ])\n",
    "\n",
    "  # Perform geometric verification using RANSAC.\n",
    "  _, inliers = ransac(\n",
    "      (locations_1_to_use, locations_2_to_use),\n",
    "      AffineTransform,\n",
    "      min_samples=3,\n",
    "      residual_threshold=20,\n",
    "      max_trials=1000)\n",
    "\n",
    "  print('Found %d inliers' % sum(inliers))\n",
    "\n",
    "  # Visualize correspondences.\n",
    "  _, ax = plt.subplots()\n",
    "  img_1 = mpimg.imread(image_1_path)\n",
    "  img_2 = mpimg.imread(image_2_path)\n",
    "  inlier_idxs = np.nonzero(inliers)[0]\n",
    "  plot_matches(\n",
    "      ax,\n",
    "      img_1,\n",
    "      img_2,\n",
    "      locations_1_to_use,\n",
    "      locations_2_to_use,\n",
    "      np.column_stack((inlier_idxs, inlier_idxs)),\n",
    "      matches_color='b')\n",
    "  ax.axis('off')\n",
    "  ax.set_title('DELF correspondences')\n",
    "\n",
    "match_images(results_dict, IMAGE_1_JPG, IMAGE_2_JPG)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TF_Hub_Delf_module_ja.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
