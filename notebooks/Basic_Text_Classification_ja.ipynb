{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "映画情報サイトにあるレビューを識別する（その1）",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YGjgJiN2xrOZ"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Authors.\n",
        "\n",
        "##### Modifications Copyright 2019 Tomoaki Masuda."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w2jnRPhYxrOb",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YI1rVCDzxrOe",
        "colab": {}
      },
      "source": [
        "#@title MIT License\n",
        "#\n",
        "# Copyright (c) 2017 François Chollet\n",
        "#\n",
        "# Permission is hereby granted, free of charge, to any person obtaining a\n",
        "# copy of this software and associated documentation files (the \"Software\"),\n",
        "# to deal in the Software without restriction, including without limitation\n",
        "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
        "# and/or sell copies of the Software, and to permit persons to whom the\n",
        "# Software is furnished to do so, subject to the following conditions:\n",
        "#\n",
        "# The above copyright notice and this permission notice shall be included in\n",
        "# all copies or substantial portions of the Software.\n",
        "#\n",
        "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
        "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
        "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
        "# DEALINGS IN THE SOFTWARE."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96sUuJdYp6CU",
        "colab_type": "text"
      },
      "source": [
        "このノートブックは、以下のノートブックを元に日本語訳、一部章立ての再構成、加筆を行いました。https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/basic_text_classification.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GBj2ktQDxrOh"
      },
      "source": [
        "\n",
        "# 映画情報サイトにあるレビューを識別する\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oKQ5YSCexrOj"
      },
      "source": [
        "\n",
        "このノートブックは、映画レビューの文章を、*ポジティブな評価*か*ネガティブな評価*かの二種類に分類します。これは、二項分類や二クラス分類と呼ばれ、重要かつ幅広く使える機械学習のタスクのひとつです。 \n",
        "\n",
        " [Internet Movie Database](https://www.imdb.com/)から5万の映画レビュー文章を集めたデータセットである、[IMDBデータセット](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb)を使います。これは学習用2万5千レビューとテスト用2万5千レビューに分けられます。学習セットとテストセットはポジティブ、ネガティブ同数のレビューが含まれます（balanced）。 \n",
        "\n",
        "このノートブックはTensorFlowでモデルを構築し学習するための高レベルAPI [tf.keras](https://www.tensorflow.org/guide/keras)を使います。 `tf.keras`を使用したより高度なテキスト分類チュートリアルは、 [MLCCテキスト分類ガイド](https://developers.google.com/machine-learning/guides/text-classification/)を参照してください。 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aibHm5ydp6CW",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## A. 環境を準備する\n",
        "\n",
        "必要なライブラリのインストール、インポートを行います。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfHmj_Bisaka",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "be5ebbc9-e72a-4d0c-9631-475393c0f62a"
      },
      "source": [
        "\"\"\" imdb.load_data で \"ValueError: Object arrays cannot be loaded when allow_pickle=False\" \n",
        "が起きるのを防ぐためにnumpyをダウングレード\n",
        "(参照：https://stackoverflow.com/questions/55824625/how-to-fix-object-arrays-cannot-be-loaded-when-allow-pickle-false-in-the-sketc)\n",
        "\"\"\"\n",
        "!pip install numpy==1.16.2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.16.2 in /usr/local/lib/python3.6/dist-packages (1.16.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5iguN9LGxrOk",
        "outputId": "fd7ecc95-074b-418e-83b4-3162a863385a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAqGNZ44p6Cc",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## B. データセットを準備する\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lXI8AdMuxrOm"
      },
      "source": [
        "### 1. IMDBデータセットをダウンロードする\n",
        "\n",
        " IMDBデータセットはTensorFlowに同梱されています。レビュー（単語の並び）が整数の並びに変換されるよう、すでに前処理されています。各整数は辞書内の特定の単語を表します。 \n",
        "\n",
        "次のコードで、IMDBデータセットをダウンロードします（すでにダウンロード済みの場合はキャッシュコピーを使用します）。 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_vY-ROKbxrOn",
        "colab": {}
      },
      "source": [
        "imdb = keras.datasets.imdb\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "It6WhG12xrOq"
      },
      "source": [
        "\n",
        "引数`num_words=10000`で、学習データセット中、最も頻繁に出現する上位1万語のみ保持するよう指定します。データのサイズが大きくなり過ぎないよう、あまり出てこない単語は破棄されます。 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "AvRq7MeQxrOr"
      },
      "source": [
        "\n",
        "### 2. データセットの中身を見てみる\n",
        "\n",
        "少し時間をかけて、データのフォーマットを理解しましょう。データセットは前処理されています。各例は、映画レビューの単語を表す整数の並び（配列）です。各ラベルは0または1の整数値です。0は否定的なレビュー、1は肯定的なレビューを表します。 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VaTgE3KyKMmk"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7Qu3dfyDxrOt",
        "outputId": "b6e9c78b-6214-44fc-9a11-c84df5c6fdc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training entries: 25000, labels: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "d504bc4UxrOx"
      },
      "source": [
        "\n",
        "レビューのテキストは整数に変換され、各整数は辞書内にある単語を表します。最初のレビューは次のようになります。 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XcykwkYBxrOy",
        "outputId": "ea0c2696-cdbe-4b8a-909d-917dd2f1e760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a4Mls2KHxrO3"
      },
      "source": [
        "\n",
        "映画のレビュー文は、それぞれ長さが異なります。以下のコードで、最初のレビューと2番目のレビューの単語数を確認してみましょう。一般に、ニューラルネットワークへの入力は同じ長さである必要があります。後でこの問題を解決しましょう。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5azJ69ToxrO4",
        "outputId": "09daa0e8-6e38-4fa9-8a3b-0b39b6918817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218, 189)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ra11Xz_nxrO5"
      },
      "source": [
        "\n",
        "### 3. 整数を単語に戻す\n",
        "\n",
        "整数をテキストに変換して戻す方法を知っておくと便利です。ここでは、整数から文字列への対応づけを持つ辞書オブジェクトへ、問い合わせをするためのヘルパー関数を作ります。 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ByGieyTrxrO6",
        "colab": {}
      },
      "source": [
        "# A dictionary mapping words to an integer index\n",
        "word_index = imdb.get_word_index()\n",
        "\n",
        "# The first indices are reserved\n",
        "word_index = {k:(v+3) for k,v in word_index.items()} \n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9y8HH1AoxrO8"
      },
      "source": [
        "\n",
        "これで`decode_review`関数を使って最初のレビューのテキストを表示することができます。 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f-KYJS3axrO9",
        "outputId": "2ed4cc0c-9297-4996-8c22-b4388757e531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "decode_review(train_data[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GVyXzVW7xrO_"
      },
      "source": [
        "\n",
        "## C. データセットを前処理する\n",
        "\n",
        "レビュー（整数の配列）は、ニューラルネットワークへ入力する前にテンソルに変換します。変換には、いくつか方法があります。 \n",
        "\n",
        "- ワンホットエンコーディングと同様、配列を単語の出現を示す0と1のベクトルに変換します。たとえば、シーケンス `[3、5]` は、1であるインデックス3と5を除いて、すべて0の1万次元ベクトルになります。次に、これをネットワークの最初の層、つまり、浮動小数点のベクトルデータを処理できる全結合層にします。ただし、この方法では大量のメモリが必要です。 `num_words * num_reviews`の形をもつ行列を保持するからです。 \n",
        "- 代わりに、すべて同じ長さになるように配列をパディングしてから、`max_length * num_reviews`の形をもつ整数テンソルを作成することもできます。この形状を処理できるembedding層をネットワークの最初の層として使います。\n",
        "\n",
        "このチュートリアルでは、後者を使います。 \n",
        "\n",
        "入力の映画レビューを同じ長さである必要があるので、 [pad_sequences](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences)関数を使い、長さを標準化します。 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vLU5uhCyxrPA",
        "colab": {}
      },
      "source": [
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=256)\n",
        "\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nejMKis6xrPD"
      },
      "source": [
        "\n",
        "例の長さを見てみましょう。 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BB-683yQxrPE",
        "outputId": "0d765b4f-0ce6-4849-db68-5cc213f06bcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(train_data[0]), len(train_data[1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WGTQ2XeJxrPJ"
      },
      "source": [
        "\n",
        "そして、（今はパディングされた）最初のレビューを調べます。 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mzyoemxxxrPJ",
        "outputId": "fcf0c94f-eaa1-484d-c933-5c3100efa081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
            "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
            "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
            "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
            " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
            "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
            "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
            " 5244   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
            "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
            "   52    5   14  407   16   82    2    8    4  107  117 5952   15  256\n",
            "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
            "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
            " 2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
            "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
            "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
            "  103   32   15   16 5345   19  178   32    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TpUMYWyHxrPO"
      },
      "source": [
        "\n",
        "## D. モデルを作成する\n",
        "\n",
        "ニューラルネットワークは、レイヤを連ねる、または重ねて作ります。構造（アーキテクチャ）を決める、2つ重要なポイントがあります。\n",
        "\n",
        "- モデルにいくつのレイヤを使うか？\n",
        "- 各層にいくつの*ノード*を使うか？ \n",
        "\n",
        "この例では、入力は単語インデックスの配列です。出力される予測ラベルは0か1のいずれかです。この課題を解くモデルを作りましょう。 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7qtgBGp_xrPO",
        "outputId": "14ab2724-145e-4b85-ff4e-87a3c549d636",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "# input shape is the vocabulary count used for the movie reviews (10,000 words)\n",
        "vocab_size = 10000\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, 16))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
        "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 16)          160000    \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 160,289\n",
            "Trainable params: 160,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pEJ5VVuRxrPU"
      },
      "source": [
        "\n",
        "これらの層を順番に積み重ねて分類器を作ります。\n",
        "\n",
        "1. 最初の層は`Embedding`層です。この層は整数で表された単語を取り、各単語のインデックスに対応した単語の埋め込みベクトル（または、単語の分散表現）を返します。これらの埋め込みベクトルも、モデルの学習が進むのと同時に、学習が進みます。ベクトルは出力配列に次元を追加します。結果得られる次元は`(batch, sequence, embedding)`です。 \n",
        "1. 次に、 `GlobalAveragePooling1D`レイヤは、シーケンスにある単語毎の埋め込みベクトルの各次元を、単語横断で平均をとることで、各レビューに対応する固定長出力ベクトルを返します。これで、モデルは可変長の入力を固定長として扱えるようになります。平均を取るのは、考えうる限り一番簡単な方法でしょう。 \n",
        "1. この固定長出力ベクトルは、16個のノードを持つ全結合層（ `Dense` ）を通り、処理されます。 \n",
        "1. 最終層の単一の出力ノードとは、全結合で接続されます。 `sigmoid`を活性化関数として使い、出力ノードの値は0から1の間の浮動小数点数(float型)として、確率、または確信度を表します。 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FIYsvn-RxrPV"
      },
      "source": [
        "\n",
        "### 1. ノード（隠れユニット）\n",
        "\n",
        "\n",
        "上記のモデルには、入力と出力の間に2つの中間層（または、隠れ層）があります。出力数（ユニット、ノード、またはニューロンと呼びます）は、レイヤが表現できる空間の次元です。言い換えると、内部表現を学習するときにネットワークが許容する自由度です。 \n",
        "\n",
        "モデルがより多くのノード（高次元の表現空間）やレイヤを持つと、ネットワークはより複雑な表現を学ぶことができます。しかし、同時にネットワークの計算コストが高くなり、不要なパターン（つまり学習データでの精度は向上するが、テストデータでの精度は向上しないパターン）の学習をしてしまうことがあります。これは*過学習*と呼ばれており、後で触れます。 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cGiwZcACxrPW"
      },
      "source": [
        "\n",
        "### 2. 損失関数とオプティマイザ\n",
        "\n",
        "モデルには、損失関数と学習用のオプティマイザが必要です。今回の課題は、二項分類問題です。モデルは確率（活性化関数としてのSigmoid関数を含む単一層）を出力するので、 `binary_crossentropy` という損失関数を使います。 \n",
        "\n",
        "損失関数は他にも選ぶことができます。例えば、 `mean_squared_error`が選べます。ただ一般に、 `binary_crossentropy`は、確率を扱うのに適しています。確率分布間、またはこの場合は正解データの分布と予測データの分布間の「距離」を測定します。 \n",
        "\n",
        "後に回帰問題をみてゆくとき（たとえば家の価格を予測するとき）、平均二乗誤差と呼ばれる別の損失関数を使います。\n",
        "\n",
        "次に、指定したオプティマイザと損失関数を使うよう、下の関数でモデルをコンパイルします。 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Efbx8v3wxrPX",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIjNsfCKp6Db",
        "colab_type": "text"
      },
      "source": [
        "## E. モデルを学習させる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "12DJ2q7qxrPZ"
      },
      "source": [
        "\n",
        "### 1. 検証データセットを準備する\n",
        "\n",
        "学習中、モデルの精度を未知のデータで確認します（検証、Validation）。そのため、元の学習データから10,000個の例を分けて、*検証データセット*を準備します。\n",
        "\n",
        "なぜ今テストデータセットを使わないのでしょうか？なぜなら、学習データのみを使用してモデルを学習・調整し、その間に検証データセットを使います。そして、次にテストデータを1回だけ使用して精度を評価したいからです。 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qy23KniexrPa",
        "colab": {}
      },
      "source": [
        "x_val = train_data[:10000]\n",
        "partial_x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "partial_y_train = train_labels[10000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4cwmnVW_xrPc"
      },
      "source": [
        "\n",
        "### 2. モデルを学習させる\n",
        "\n",
        " 512サンプルのミニバッチで40エポック、モデルを学習させます。これは、`x_train`と`y_train`テンソルの全サンプルを、40回繰り返し使って学習します。学習中に、検証セットからの1万サンプルでモデルの誤差(loss)と精度を監視します。 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YFQp5YG4xrPc",
        "outputId": "6641ac02-29a3-4f62-e0e7-d175b909885e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1515
        }
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=40,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    verbose=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15000 samples, validate on 10000 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/40\n",
            "15000/15000 [==============================] - 1s 51us/sample - loss: 0.6911 - acc: 0.6663 - val_loss: 0.6886 - val_acc: 0.7237\n",
            "Epoch 2/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.6842 - acc: 0.7221 - val_loss: 0.6793 - val_acc: 0.7336\n",
            "Epoch 3/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.6699 - acc: 0.7570 - val_loss: 0.6616 - val_acc: 0.7458\n",
            "Epoch 4/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.6458 - acc: 0.7691 - val_loss: 0.6346 - val_acc: 0.7472\n",
            "Epoch 5/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.6116 - acc: 0.7958 - val_loss: 0.5992 - val_acc: 0.7839\n",
            "Epoch 6/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.5689 - acc: 0.8157 - val_loss: 0.5584 - val_acc: 0.8108\n",
            "Epoch 7/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.5217 - acc: 0.8355 - val_loss: 0.5144 - val_acc: 0.8221\n",
            "Epoch 8/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.4746 - acc: 0.8509 - val_loss: 0.4739 - val_acc: 0.8369\n",
            "Epoch 9/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.4309 - acc: 0.8665 - val_loss: 0.4375 - val_acc: 0.8459\n",
            "Epoch 10/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.3924 - acc: 0.8769 - val_loss: 0.4075 - val_acc: 0.8536\n",
            "Epoch 11/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.3597 - acc: 0.8852 - val_loss: 0.3827 - val_acc: 0.8611\n",
            "Epoch 12/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.3322 - acc: 0.8918 - val_loss: 0.3634 - val_acc: 0.8645\n",
            "Epoch 13/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.3097 - acc: 0.8972 - val_loss: 0.3466 - val_acc: 0.8701\n",
            "Epoch 14/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.2894 - acc: 0.9032 - val_loss: 0.3343 - val_acc: 0.8739\n",
            "Epoch 15/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.2725 - acc: 0.9067 - val_loss: 0.3243 - val_acc: 0.8746\n",
            "Epoch 16/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.2573 - acc: 0.9122 - val_loss: 0.3158 - val_acc: 0.8765\n",
            "Epoch 17/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.2433 - acc: 0.9162 - val_loss: 0.3087 - val_acc: 0.8781\n",
            "Epoch 18/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.2309 - acc: 0.9212 - val_loss: 0.3028 - val_acc: 0.8811\n",
            "Epoch 19/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.2198 - acc: 0.9239 - val_loss: 0.2977 - val_acc: 0.8829\n",
            "Epoch 20/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.2097 - acc: 0.9279 - val_loss: 0.2943 - val_acc: 0.8822\n",
            "Epoch 21/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.1995 - acc: 0.9331 - val_loss: 0.2913 - val_acc: 0.8834\n",
            "Epoch 22/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.1910 - acc: 0.9359 - val_loss: 0.2891 - val_acc: 0.8842\n",
            "Epoch 23/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.1824 - acc: 0.9405 - val_loss: 0.2879 - val_acc: 0.8837\n",
            "Epoch 24/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.1749 - acc: 0.9437 - val_loss: 0.2861 - val_acc: 0.8854\n",
            "Epoch 25/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.1673 - acc: 0.9468 - val_loss: 0.2850 - val_acc: 0.8856\n",
            "Epoch 26/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.1604 - acc: 0.9500 - val_loss: 0.2855 - val_acc: 0.8831\n",
            "Epoch 27/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.1540 - acc: 0.9522 - val_loss: 0.2851 - val_acc: 0.8851\n",
            "Epoch 28/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.1479 - acc: 0.9546 - val_loss: 0.2853 - val_acc: 0.8850\n",
            "Epoch 29/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.1426 - acc: 0.9578 - val_loss: 0.2875 - val_acc: 0.8836\n",
            "Epoch 30/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.1370 - acc: 0.9593 - val_loss: 0.2867 - val_acc: 0.8863\n",
            "Epoch 31/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.1314 - acc: 0.9613 - val_loss: 0.2879 - val_acc: 0.8867\n",
            "Epoch 32/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.1262 - acc: 0.9643 - val_loss: 0.2894 - val_acc: 0.8863\n",
            "Epoch 33/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.1214 - acc: 0.9656 - val_loss: 0.2918 - val_acc: 0.8836\n",
            "Epoch 34/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.1170 - acc: 0.9671 - val_loss: 0.2935 - val_acc: 0.8858\n",
            "Epoch 35/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.1129 - acc: 0.9680 - val_loss: 0.2967 - val_acc: 0.8839\n",
            "Epoch 36/40\n",
            "15000/15000 [==============================] - 0s 18us/sample - loss: 0.1086 - acc: 0.9705 - val_loss: 0.2983 - val_acc: 0.8846\n",
            "Epoch 37/40\n",
            "15000/15000 [==============================] - 0s 19us/sample - loss: 0.1044 - acc: 0.9716 - val_loss: 0.3007 - val_acc: 0.8843\n",
            "Epoch 38/40\n",
            "15000/15000 [==============================] - 0s 20us/sample - loss: 0.1006 - acc: 0.9728 - val_loss: 0.3042 - val_acc: 0.8832\n",
            "Epoch 39/40\n",
            "15000/15000 [==============================] - 0s 21us/sample - loss: 0.0975 - acc: 0.9739 - val_loss: 0.3074 - val_acc: 0.8824\n",
            "Epoch 40/40\n",
            "15000/15000 [==============================] - 0s 21us/sample - loss: 0.0935 - acc: 0.9762 - val_loss: 0.3096 - val_acc: 0.8819\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KtrnLQqNxrPj"
      },
      "source": [
        "\n",
        "## F. 学習済みモデルを評価する\n",
        "\n",
        "学習したモデルの性能を見てみましょう。以下の2つの値が返されます。\n",
        "\n",
        "- 誤差（私たちのエラーを表す数値、低い値の方が優れています）\n",
        "- 精度 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SvGYTAIuxrPj",
        "outputId": "87c9ac5c-01ec-42b2-a8fe-3e9dd015f3c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "results = model.evaluate(test_data, test_labels)\n",
        "\n",
        "print(results)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 1s 55us/sample - loss: 0.3307 - acc: 0.8719\n",
            "[0.3307314974832535, 0.87188]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GCI3laxDxrPl"
      },
      "source": [
        "\n",
        "このような、とても素朴なアプローチでも、約87％の精度を達成できました。より高度なアプローチでは、モデルは95％に近づくはずです。 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mdcPGcGYxrPm"
      },
      "source": [
        "\n",
        "### 1. 精度と誤差(loss)の時系列グラフを作成する\n",
        "\n",
        " `model.fit()`は、学習中に起こったことすべてを含む辞書を含む`History`オブジェクトを返します。 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JOkHmBPQxrPn",
        "outputId": "9b279612-cb19-44bb-fa65-93a5737f5704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g6OaI8IkxrPp"
      },
      "source": [
        "\n",
        "学習中の、以下4つの値の推移が保存されています。\n",
        "\n",
        "- acc 学習データセットに対する精度\n",
        "- loss　学習データセットに対する誤差\n",
        "- val_acc　検証データセットに対する精度\n",
        "- val_loss　検証データセットに対する誤差\n",
        "\n",
        "学習および検証中に監視される各メトリックに1つです。これらを使って、比較のために学習・検証データセットの誤差、精度（正解率）をプロットできます。 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "luU9i7G9xrPp",
        "outputId": "dce3732c-a45c-4ae1-d1df-22f19b33fa4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiJSRklBRETKKCmIiEgZJQURESnz/wCOBjd9BGQ5PgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uWTEWhHAxrPq",
        "outputId": "26a50a1a-f588-4c33-9a33-857a3d2c7f6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.clf()   # clear figure\n",
        "acc_values = history_dict['acc']\n",
        "val_acc_values = history_dict['val_acc']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkoWIiKT0/wGJ5Uq78IlLNwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mdchyra1xrPu"
      },
      "source": [
        "\n",
        "このプロットでは以下を表します。\n",
        "\n",
        "- 点線は学習データセットの誤差と精度\n",
        "- 実線は検証データセットの誤差と精度\n",
        "\n",
        "学習時の誤差が各エポックで*減少*し、精度が各エポックで*増加*することに注目してください。これは、勾配降下法による最適化を使うと、見られる動きです。エポックを反復するごとに、誤差が最小になるよう、パラメータを調整していきます。 \n",
        "\n",
        "しかし、検証データセットの誤差と精度には当てはまりません。約20エポックでピークに達したようです。これは過学習の兆候を示しています。モデルは、学習データセットに対して、未知のデータセットよりも優れた精度を示します。20エポックを超えると、モデルはテストデータに現れない、学習データセットに固有の表現を過度に最適化して学習してしまったようです。\n",
        "\n",
        "このケースでは、20回程度のエポックの後、単にトレーニングを中止することで、過学習を防げます。コールバックを使って、学習の自動停止をする方法もあります。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J7Y5l2UYfJxm",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}